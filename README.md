# MalwareMLPBatchNorm

This repository is part of the project developed for the exam of Deep Learning and Applied Artificial Intelligence taught by Emanuele Rodolà at La Sapienza University of Rome, Fall 2022.

The aim of the present project is to discuss and test a phenomena happening while training a neural network built with batch normalization. In the paper ["Training BatchNorm and Only BatchNorm: On the Expressive Power of Random Features in CNN"](https://arxiv.org/abs/2003.00152) taken as main route for the focus of the project it has been found out that A CNN with weights frozen at their random original value and trained only on the β and γ parameters of the batch-normalization can achieve surprisingly good results on image classification problems. The following sections explain why it happens and show the process I undertook to test experimentally this result on other architectures and other kinds of data.

The project makes use of:

[Weights and Biases](https://wandb.ai/site), to organize and analyze the experiments<br />
[Streamlit](https://streamlit.io/), to turn data scripts into shareable web apps

Notes: <br />
   On startup, the webapp automatically connects to wandb. Check the official documentation to set up the environment first<br />
   Every now and then, wandb blocks the program flow. It is enough to press enter in the terminal opened to run streamlit: wandb will continue working.

## Installation

Use the package manager [pip](https://pip.pypa.io/en/stable/) to install the requirements.

```bash
pip install -r requirements.txt
```

