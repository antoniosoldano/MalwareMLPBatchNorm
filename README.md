# MalwareMLPBatchNorm

This repository is part of the project developed for the exam of Deep Learning and Applied Artificial Intelligence taught by Emanuele Rodolà at La Sapienza University of Rome, Fall 2022.

The aim of the present project is to discuss and test a phenomena happening while training a neural network built with batch normalization. In the paper ["Training BatchNorm and Only BatchNorm: On the Expressive Power of Random Features in CNN"](https://arxiv.org/abs/2003.00152) taken as main route for the focus of the project it has been found out that A CNN with weights frozen at their random original value and trained only on the β and γ parameters of the batch-normalization can achieve surprisingly good results on image classification problems. The following sections explain why it happens and show the process I undertook to test experimentally this result on other architectures and other kinds of data.

The project makes use of:

[Weights and Biases](https://wandb.ai/site), to organize and analyze the experiments<br />
[Streamlit](https://streamlit.io/), to turn data scripts into shareable web apps

Notes: <br />
On startup, the webapp automatically connects to wandb. Check the official documentation to set up the environment first<br />
Every now and then, wandb blocks the program flow. It is enough to press enter in the terminal opened to run streamlit: wandb will continue working.

## Project structure

```bash
MalwareMLPBatchNorm
|
|   0_Home.py (starting point of the app: Main page)
|   config.py (configuration file: defines paths and names)
|   requirements.txt (project requirements)
|
|---classes
|       MalwareDataset.py (Custom class that extends the Dataset one)
|       MultilayerPerceptron.py (Custom class for the MLP)
|       DeeperMultilayerPerceptron.py (Second custom class for the MLP)
|
|---dataset
|       dike_dataset.csv (samples extracted features for the Dike dataset are stored here)
|       dike_dataset_count.csv (count of the previous one)
|       thezoo_dataset.csv (samples extracted features for the The Zoo dataset are stored here)
|       thezoo_dataset_count.csv (count of the previous one)
|
|---extract_pe_features_scripts
|       extract_pe_features_dike.py (script used to extract features from the Dike dataset)
|       extract_pe_features_zoo.py (script used to extract features from the The Zoo dataset)
|
|---pages
|       1_Datasets_Navigation.py (Page to navigate trough the datasets)
|       2_Dike Playground.py (Page to play with the first dataset)
|       3_The Zoo Playground.py (Page to play with the second dataset)
|       4_The Deeper Zoo Playground.py (Page to play with the second dataset and the second MLP)
|
|---wandb (auto-generated)
```
## Installation
Use the package manager [pip](https://pip.pypa.io/en/stable/) to install the requirements.

```bash
pip install -r requirements.txt
```
## Run

Just run the webapp with Streamlit

```bash
python -m streamlit run 0_Home.py
```
