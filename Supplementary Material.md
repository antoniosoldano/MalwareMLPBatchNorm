## Features Extraction

Here an in-depth analysis on how the data used for the project has been extracted.
As has been already said in the main report, the data used refer to malware executable files. In particular, the features extracted from those samples are treated as float data type, stored in arrays of 34 elements, extracted from the PE headers \cite{microsoftpeformat}:
*The PE format is a data structure that encapsulates the information necessary for the Windows OS loader to manage the wrapped executable code. This includes dynamic library references for linking, API export and import tables, resource management data and thread-local storage (TLS) data.* \cite{wikipediape}
The reason why I used this kind of data lie on the fact that some specific fields are meaningful to identify malware executables. Some examples:

-**Abnormal section sizes**: The **Raw data** section is way smaller than the **Virtual Size** section, symptom of {Packed Code \cite{packedcode}
-**Sections Writable and Executable**: Usually the sections are only readable. If we find a section is also writable and executable, it is a symptom of a malware sample

By running the code, the datasets and the relative PE fields can be inspected in the section **Datasets Navigation**
The entire algorithm for the extraction of the PE features has been taken from \cite{prajapatigithub}.

## Increasing the model complexity

The complexity of the model can also impact its accuracy. Since a model that is too simple may be unable to capture the underlying patterns in the data, the Multi Layer Perceptron has been extended with more linear layers, as it allows the model to learn more complex patterns and relationships in the data. Then, it has been run with the same runs of the \autoref{tab:thezooruns}.
Mainly, with respect to the architecture 1, for some runs it is slower to converge because it has more parameters to optimize, which means that the optimization process has to work harder to find good values for all of these parameters but it does not reach better results.
In conclusion, the model complexity does not affect significatly the accuracy of the network.

## Beta and Gamma values

It is known that the beta and gamma parameters can play a significant role in the performance of learning model. In this case, they has been used to adjust the activations of each layer in order to improve the stability and generalization performance of the model and compensate for the lack of flexibility in the linear layers, or to correct for any biases or imbalances in the training data.
In the section 5 of the paper \cite{DBLP:journals/corr/abs-2003-00152}, the authors found that when the network was trained by freezing the parameters of the layers at their initial value and trainin over only the affine one, the values of beta tended to converge to zero, while the values of gamma tended to converge to one.
In the present project, the same results were highlighted, shown above in \autoref{fig:betavalues} and \autoref{fig:gammavalues}.
Both the values of $\beta$ and $\gamma$ are distributed widely in the only batchnorm runs as at is has been shown in the related work: this means that batch normalization "sparsifies activations" i.e. by normalizing the activations, batch normalization can help to ensure that the activations stay within a more reasonable range, which can help to prevent saturation and encourage more sparse activations.\break Also, the values of beta and gamma tended to converge more quickly when the network was trained on larger datasets. This suggests that the batch normalization parameters may be able to capture more information from the data when the network is trained on a larger dataset, both in terms of number of samples (like Dike Dataset) or in terms of complexity (The Zoo).
